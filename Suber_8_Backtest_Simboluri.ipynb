{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====== Param vectors (self-contained) + mapping, MAC-Z exclus ======\n",
    "\n",
    "def prepare_optimization_vectors():\n",
    "    # defaults fallback (dacă nu au fost definite în alte celule)\n",
    "    global indicator_params_default, short_params_default\n",
    "    if \"indicator_params_default\" not in globals():\n",
    "        indicator_params_default = {\n",
    "            \"fEma_Length\": 61, \"sEma_Length\": 444,\n",
    "            \"ADX_len\": 15, \"ADX_smo\": 10, \"th\": 5.47,\n",
    "            \"fastLength\": 20, \"slowLength\": 43, \"signalLength\": 12,  # MACD clasic\n",
    "            \"MACD_options\": \"MACD\",\n",
    "            \"BB_Length\": 89, \"BB_mult\": 6.281,\n",
    "            \"sma_Length\": 81, \"volume_f\": 0.87,\n",
    "            \"DClength\": 79,\n",
    "            \"Sst\": 0.10, \"Sinc\": 0.04, \"Smax\": 0.40,\n",
    "            \"bbMinWidth01\": 9.3,\n",
    "            \"lengthz\": 14, \"lengthStdev\": 16, \"A\": -0.1, \"B\": 0.5, \"bbMinWidth02\": 0.0\n",
    "        }\n",
    "    if \"short_params_default\" not in globals():\n",
    "        short_params_default = {\n",
    "            \"tp\": 3.6, \"sl\": 8.0,\n",
    "            \"atrPeriodSl\": 50, \"multiplierPeriodSl\": 36.84, \"trailOffset\": 0.38,\n",
    "            \"reverse_exit\": True, \"exit_on_entry_loss\": False,\n",
    "            \"Position\": \"Short\"\n",
    "        }\n",
    "\n",
    "    # --- adăugăm fEma_Length, sEma_Length și ADX_smo în optimizare ---\n",
    "    indicator_params_to_optimize = [\n",
    "        \"fEma_Length\", \"sEma_Length\",\n",
    "        \"ADX_len\", \"ADX_smo\", \"th\",\n",
    "        \"fastLength\", \"slowLength\", \"signalLength\",\n",
    "        \"BB_Length\", \"BB_mult\",\n",
    "        \"DClength\"\n",
    "    ]\n",
    "    short_params_to_optimize = [\n",
    "        \"atrPeriodSl\", \"multiplierPeriodSl\"\n",
    "    ]\n",
    "\n",
    "    # excludem MAC-Z din optimizare\n",
    "    MACZ_KEYS = {\"MACD_options\", \"lengthz\", \"lengthStdev\", \"A\", \"B\"}\n",
    "    names = [n for n in (indicator_params_to_optimize + short_params_to_optimize) if n not in MACZ_KEYS]\n",
    "\n",
    "    # categorii (rotunjiri / bounds)\n",
    "    LENGTH_INTS = {\n",
    "        \"fEma_Length\", \"sEma_Length\", \"ADX_len\", \"ADX_smo\",\n",
    "        \"fastLength\", \"slowLength\", \"signalLength\",\n",
    "        \"BB_Length\", \"sma_Length\", \"DClength\", \"atrPeriodSl\"\n",
    "    }\n",
    "    SAR_FLOATS = {\"Sst\", \"Sinc\", \"Smax\"}\n",
    "    PCT_FLOATS = {\"tp\", \"sl\", \"bbMinWidth01\"}  # procente\n",
    "    POS_FLOATS = {\"BB_mult\", \"volume_f\", \"th\", \"multiplierPeriodSl\"}  # >0\n",
    "    SHORT_FLOATS = {\"trailOffset\"}  # >=0\n",
    "\n",
    "    # extinderi UNILATERALE acolo unde s-au lovit capetele\n",
    "    # multiplicatori relativi la default (lo_mult, hi_mult)\n",
    "    BOUND_OVERRIDES = {\n",
    "        # ADX – ai lovit capătul inferior la len; coborâm și mai jos\n",
    "        \"ADX_len\": (0.48, 1.17),              # 21 -> [~10, 25]\n",
    "        \"ADX_smo\": (0.40, 1.40),              # 14 -> [~6, 20]  (validat oricum cu ADX_smo ≤ ADX_len)\n",
    "\n",
    "        # prag ADX\n",
    "        \"th\":      (0.33, 2.50),            \n",
    "\n",
    "        # EMA – ușor mai sus la fast; slow rămâne cum e (nu era la capăt)\n",
    "        \"fEma_Length\": (0.83, 1.30),          # 65 -> [54, 84]\n",
    "        # \"sEma_Length\": (0.83, 1.17),        # lăsăm default (nu era la capăt)\n",
    "\n",
    "        # BB – ai lovit capetele superioare, lărgim în sus\n",
    "        \"BB_Length\": (0.83, 1.75),            # 51 -> [42, ~89]\n",
    "        \"BB_mult\":  (0.50, 2.10),             # 3.0 -> [1.5, 6.3]\n",
    "\n",
    "        # Donchian – ok cum e; îl lăsăm default\n",
    "        # \"DClength\": (0.83, 1.17),\n",
    "\n",
    "        # SL ATR – ai lovit capetele superioare, lărgim în sus\n",
    "        \"atrPeriodSl\": (0.50, 2.00),          # 25 -> [12, 50]\n",
    "        \"multiplierPeriodSl\": (0.50, 2.60),   # 14.25 -> [7.12, ~37.05]\n",
    "    }\n",
    "\n",
    "\n",
    "    start_params, bounds = [], []\n",
    "    for name in names:\n",
    "        val = float(indicator_params_default.get(name, short_params_default.get(name)))\n",
    "        if name in LENGTH_INTS:\n",
    "            lo_mult, hi_mult = BOUND_OVERRIDES.get(name, (0.83, 1.17))\n",
    "            lo = max(2, int(round(val * lo_mult)))\n",
    "            hi = max(lo + 1, int(round(val * hi_mult)))\n",
    "            start_params.append(int(round(val)))\n",
    "            bounds.append((lo, hi))\n",
    "        elif name in SAR_FLOATS:\n",
    "            lo = 0.01 if name == \"Sst\" else 0.02\n",
    "            hi = 1.0 if name == \"Smax\" else 0.5\n",
    "            start_params.append(val)\n",
    "            bounds.append((lo, hi))\n",
    "        elif name in PCT_FLOATS or name in POS_FLOATS or name in SHORT_FLOATS:\n",
    "            lo_mult, hi_mult = BOUND_OVERRIDES.get(name, (0.50, 1.50))\n",
    "            lo = max(0.0, val * lo_mult)\n",
    "            hi = val * hi_mult\n",
    "            start_params.append(val)\n",
    "            bounds.append((lo, hi))\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "    return names, tuple(start_params), tuple(bounds)\n",
    "\n",
    "\n",
    "def vector_to_param_dicts(x, names):\n",
    "    \"\"\"Mapează vectorul x -> (indicator_params, short_params), cu rotunjiri corecte, MACD clasic și cuantizare pe continui.\"\"\"\n",
    "    indicator_params = indicator_params_default.copy()\n",
    "    short_params = short_params_default.copy()\n",
    "\n",
    "    int_params = {\n",
    "        \"fEma_Length\", \"sEma_Length\", \"ADX_len\", \"ADX_smo\",\n",
    "        \"fastLength\", \"slowLength\", \"signalLength\",\n",
    "        \"sma_Length\", \"BB_Length\", \"DClength\", \"atrPeriodSl\"\n",
    "    }\n",
    "    # pas minim pe câțiva continui (evită micro-rafinări fără impact material)\n",
    "    QUANTIZE = {\n",
    "        \"th\": 0.1,\n",
    "        \"BB_mult\": 0.1,\n",
    "        \"multiplierPeriodSl\": 0.25\n",
    "    }\n",
    "\n",
    "    for name, v in zip(names, x):\n",
    "        if name in int_params:\n",
    "            val = max(1, int(round(v)))\n",
    "        else:\n",
    "            val = float(v)\n",
    "            if name in QUANTIZE:\n",
    "                step = QUANTIZE[name]\n",
    "                val = round(val / step) * step\n",
    "\n",
    "        if name in indicator_params:\n",
    "            indicator_params[name] = val\n",
    "        elif name in short_params:\n",
    "            short_params[name] = val\n",
    "\n",
    "    # forțăm MACD clasic (nu MAC-Z)\n",
    "    indicator_params[\"MACD_options\"] = \"MACD\"\n",
    "    for k in (\"lengthz\", \"lengthStdev\", \"A\", \"B\"):\n",
    "        indicator_params.pop(k, None)\n",
    "\n",
    "    return indicator_params, short_params\n",
    "\n",
    "\n",
    "\n",
    "import configparser\n",
    "import os\n",
    "import time\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict, List, Optional\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "DEFAULT_DATA_DIR = os.environ.get(\"SUPER8_DATA_DIR\", \"Simboluri_Binance\")\n",
    "SYMBOLS_FILE = os.environ.get(\"SUPER8_SYMBOLS_FILE\")\n",
    "BINANCE_CFG_PATH = os.environ.get(\"BINANCE_CFG_PATH\", \"Binance.cfg\")\n",
    "RESULTS_PATH_DEFAULT = os.environ.get(\"SUPER8_RESULTS_PATH\", \"rezultate_optimizare.csv\")\n",
    "\n",
    "\n",
    "def _make_absolute(path: Path) -> Path:\n",
    "    path = path.expanduser()\n",
    "    if not path.is_absolute():\n",
    "        path = (Path.cwd() / path).resolve()\n",
    "    return path\n",
    "\n",
    "\n",
    "DATA_DIR = _make_absolute(Path(DEFAULT_DATA_DIR))\n",
    "\n",
    "\n",
    "def load_binance_credentials(cfg_path: Optional[str] = None, required: bool = False) -> Dict[str, str]:\n",
    "    \"\"\"Citește Binance.cfg și întoarce cheile API (dacă există).\"\"\"\n",
    "    cfg_file = _make_absolute(Path(cfg_path or BINANCE_CFG_PATH))\n",
    "    if not cfg_file.exists():\n",
    "        if required:\n",
    "            raise FileNotFoundError(f\"Nu am găsit fișierul de configurare Binance.cfg la {cfg_file}.\")\n",
    "        print(f\"[Avertisment] Nu am găsit Binance.cfg la {cfg_file}. Rularea backtest-ului nu necesită API key.\")\n",
    "        return {}\n",
    "\n",
    "    parser = configparser.ConfigParser()\n",
    "    parser.read(cfg_file, encoding='utf-8')\n",
    "\n",
    "    section = None\n",
    "    for candidate in (\"binance\", \"BINANCE\", \"default\", \"DEFAULT\"):\n",
    "        if candidate in parser:\n",
    "            section = parser[candidate]\n",
    "            break\n",
    "\n",
    "    if section is None:\n",
    "        raise KeyError(\"Binance.cfg trebuie să conțină o secțiune 'binance'.\")\n",
    "\n",
    "    api_key = section.get('api_key') or section.get('API_KEY') or section.get('key')\n",
    "    api_secret = section.get('api_secret') or section.get('API_SECRET') or section.get('secret')\n",
    "\n",
    "    if required and (not api_key or not api_secret):\n",
    "        raise ValueError(\"Binance.cfg nu conține câmpurile necesare 'api_key' și 'api_secret'.\")\n",
    "\n",
    "    if api_key or api_secret:\n",
    "        masked = (api_key[:6] + '***') if api_key else '<nedisponibil>'\n",
    "        print(f\"[Info] Config Binance.cfg încărcat (cheie începe cu: {masked}).\")\n",
    "\n",
    "    return {'api_key': api_key or '', 'api_secret': api_secret or ''}\n",
    "\n",
    "\n",
    "def list_available_symbols(data_dir: Optional[Path] = None) -> List[str]:\n",
    "    directory = _make_absolute(Path(data_dir or DATA_DIR))\n",
    "    if not directory.exists():\n",
    "        raise FileNotFoundError(f\"Folderul cu simboluri nu există: {directory}\")\n",
    "    return sorted({p.stem.upper() for p in directory.glob('*.csv')})\n",
    "\n",
    "\n",
    "def load_symbol_universe(symbols_file: Optional[str] = SYMBOLS_FILE, data_dir: Optional[Path] = None) -> List[str]:\n",
    "    if symbols_file:\n",
    "        file_path = _make_absolute(Path(symbols_file))\n",
    "        if not file_path.exists():\n",
    "            raise FileNotFoundError(f\"Nu am găsit fișierul cu simboluri: {file_path}\")\n",
    "        if file_path.suffix.lower() in {'.csv', '.tsv'}:\n",
    "            df = pd.read_csv(file_path)\n",
    "            for column in ('Symbol', 'symbol', 'SYMBOL'):\n",
    "                if column in df.columns:\n",
    "                    symbols = [str(v).strip().upper() for v in df[column] if str(v).strip()]\n",
    "                    if symbols:\n",
    "                        return symbols\n",
    "        symbols = [line.strip().upper() for line in file_path.read_text(encoding='utf-8').splitlines() if line.strip()]\n",
    "        if symbols:\n",
    "            return symbols\n",
    "        raise ValueError(f\"Fișierul cu simboluri {file_path} nu conține valori valide.\")\n",
    "    return list_available_symbols(data_dir)\n",
    "\n",
    "\n",
    "def save_results(df: pd.DataFrame, output_path: Optional[str] = None) -> Path:\n",
    "    if df is None or df.empty:\n",
    "        raise ValueError(\"Nu există date în results_df pentru a fi salvate.\")\n",
    "    target = _make_absolute(Path(output_path or RESULTS_PATH_DEFAULT))\n",
    "    target.parent.mkdir(parents=True, exist_ok=True)\n",
    "    df.to_csv(target, index=False)\n",
    "    print(f\"[Info] Rezultatele au fost salvate în {target}\")\n",
    "    return target\n",
    "\n",
    "\n",
    "\n",
    "def symbol_csv_path(symbol: str) -> Path:\n",
    "    \"\"\"Returnează calea completă către fișierul CSV aferent simbolului (în DATA_DIR).\"\"\"\n",
    "    safe_symbol = symbol.upper().replace('/', '_')\n",
    "    return (DATA_DIR / f\"{safe_symbol}.csv\").resolve()\n",
    "\n",
    "def symbol_csv_path_case_insensitive(symbol: str) -> Optional[Path]:\n",
    "    \"\"\"Returnează calea existentă pentru simbol (ignorând extensia .csv/.CSV).\"\"\"\n",
    "    base_name = symbol.upper().replace('/', '_')\n",
    "    candidates = [DATA_DIR / f\"{base_name}.csv\", DATA_DIR / f\"{base_name}.CSV\"]\n",
    "    for candidate in candidates:\n",
    "        if candidate.exists():\n",
    "            return candidate.resolve()\n",
    "    return None\n",
    "\n",
    "def _crossover(a: pd.Series, b: pd.Series) -> pd.Series:\n",
    "    a1 = a.shift(1); b1 = b.shift(1)\n",
    "    return (a1 <= b1) & (a > b)\n",
    "\n",
    "def _crossunder(a: pd.Series, b: pd.Series) -> pd.Series:\n",
    "    a1 = a.shift(1); b1 = b.shift(1)\n",
    "    return (a1 >= b1) & (a < b)\n",
    "\n",
    "\n",
    "# --- Helper functions for Price/Spread/Validation ---\n",
    "def _rma(series: pd.Series, period: int) -> pd.Series:\n",
    "    \"\"\"Wilder's RMA (EMA with alpha = 1/period).\"\"\"\n",
    "    alpha = 1.0 / period\n",
    "    return series.ewm(alpha=alpha, adjust=False).mean()\n",
    "\n",
    "def _ensure_price(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Ensure 'Price' column exists in df (use 'close' if present).\"\"\"\n",
    "    if \"Price\" not in df.columns:\n",
    "        if \"close\" in df.columns:\n",
    "            df[\"Price\"] = df[\"close\"]\n",
    "        else:\n",
    "            raise KeyError(\"The CSV must contain a 'Price' or 'close' column.\")\n",
    "    for col in (\"high\", \"low\", \"volume\"):\n",
    "        if col not in df.columns:\n",
    "            raise KeyError(f\"The CSV must contain column '{col}'.\")\n",
    "    return df\n",
    "\n",
    "def _k_from_barlen(bar_length: str) -> float:\n",
    "    bl = (bar_length or \"\").upper()\n",
    "    if bl in (\"M1\", \"1M\"):  return 0.08\n",
    "    if bl in (\"M5\", \"5M\"):  return 0.12\n",
    "    if bl in (\"M15\", \"15M\"): return 0.18\n",
    "    if bl in (\"H2\", \"2H\"):   return 0.26   # <- adaugă asta (valoare între H1 și H4)\n",
    "    if bl in (\"H4\", \"4H\"):   return 0.30\n",
    "    return 0.22  # default (H1)\n",
    "\n",
    "def compute_spread(df: pd.DataFrame, pay_fees_with_bnb: bool = False, bar_length: str = \"H1\") -> float:\n",
    "    \"\"\"\n",
    "    Compute per-side cost in log-return (Spread) and set df[\"Spread\"] to that constant value.\n",
    "    Spread = -ln(1 - (fee_pct + slip_pct)), where slip_pct = k * median((high-low)/Price) clipped [0.02%, 0.40%].\n",
    "    Returns the numeric spread value.\n",
    "    \"\"\"\n",
    "    df = _ensure_price(df)\n",
    "    fee_pct = 0.0010 * (0.75 if pay_fees_with_bnb else 1.0)  # Spot fee: 0.10% or 0.075% with BNB\n",
    "    rng = (df[\"high\"] - df[\"low\"]) / df[\"Price\"]\n",
    "    k = _k_from_barlen(bar_length)\n",
    "    slip_pct = float(np.clip(k * float(np.nanmedian(rng)), 0.0002, 0.0040))\n",
    "    spread_log = -np.log(1.0 - (fee_pct + slip_pct))\n",
    "    df[\"Spread\"] = spread_log\n",
    "    return spread_log\n",
    "\n",
    "def is_param_combo_valid(ind_params: Dict[str, Any], short_vals: Dict[str, Any]) -> bool:\n",
    "    # EMA: fast EMA length < slow EMA length\n",
    "    if int(ind_params[\"fEma_Length\"]) >= int(ind_params[\"sEma_Length\"]):\n",
    "        return False\n",
    "    # MACD: fast < slow\n",
    "    if int(ind_params[\"fastLength\"]) >= int(ind_params[\"slowLength\"]):\n",
    "        return False\n",
    "    # ADX: smoothing ≤ length\n",
    "    if int(ind_params.get(\"ADX_smo\", ind_params[\"ADX_len\"])) > int(ind_params[\"ADX_len\"]):\n",
    "        return False\n",
    "    # SAR: toate pozitive; start/inc ≤ max\n",
    "    if not (ind_params[\"Sst\"] > 0 and ind_params[\"Sinc\"] > 0 and ind_params[\"Smax\"] > 0):\n",
    "        return False\n",
    "    if ind_params[\"Sst\"] > ind_params[\"Smax\"] or ind_params[\"Sinc\"] > ind_params[\"Smax\"]:\n",
    "        return False\n",
    "    # Bollinger Bands\n",
    "    if int(ind_params[\"BB_Length\"]) < 5:\n",
    "        return False\n",
    "    if float(ind_params[\"BB_mult\"]) <= 0:\n",
    "        return False\n",
    "    # Donchian channel\n",
    "    if int(ind_params[\"DClength\"]) < 5:\n",
    "        return False\n",
    "    # Volume\n",
    "    if int(ind_params[\"sma_Length\"]) < 1:\n",
    "        return False\n",
    "    if float(ind_params[\"volume_f\"]) <= 0:\n",
    "        return False\n",
    "    # Short params\n",
    "    if int(short_vals[\"atrPeriodSl\"]) < 1:\n",
    "        return False\n",
    "    if float(short_vals[\"multiplierPeriodSl\"]) <= 0:\n",
    "        return False\n",
    "    if float(short_vals[\"trailOffset\"]) < 0:\n",
    "        return False\n",
    "    if float(short_vals[\"tp\"]) < 0 or float(short_vals[\"sl\"]) < 0:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "\n",
    "def why_invalid(ind_params, short_vals):\n",
    "    reasons = []\n",
    "    if int(ind_params[\"fEma_Length\"]) >= int(ind_params[\"sEma_Length\"]): reasons.append(\"fEma>=sEma\")\n",
    "    if int(ind_params[\"fastLength\"])  >= int(ind_params[\"slowLength\"]):  reasons.append(\"fast>=slow\")\n",
    "    if int(ind_params[\"ADX_smo\"])     >  int(ind_params[\"ADX_len\"]):     reasons.append(\"ADX_smo>ADX_len\")\n",
    "    if not (ind_params[\"Sst\"]>0 and ind_params[\"Sinc\"]>0 and ind_params[\"Smax\"]>0): reasons.append(\"SAR<=0\")\n",
    "    if ind_params[\"Sst\"]>ind_params[\"Smax\"] or ind_params[\"Sinc\"]>ind_params[\"Smax\"]: reasons.append(\"SAR start/inc > max\")\n",
    "    if int(ind_params[\"BB_Length\"])<5 or float(ind_params[\"BB_mult\"])<=0: reasons.append(\"BB invalid\")\n",
    "    if int(ind_params[\"DClength\"])<5: reasons.append(\"DC<5\")\n",
    "    if int(ind_params[\"sma_Length\"])<1 or float(ind_params[\"volume_f\"])<=0: reasons.append(\"volume invalid\")\n",
    "    if int(short_vals[\"atrPeriodSl\"])<1 or float(short_vals[\"multiplierPeriodSl\"])<=0 or float(short_vals[\"trailOffset\"])<0:\n",
    "        reasons.append(\"SL invalid\")\n",
    "    if float(short_vals[\"tp\"])<0 or float(short_vals[\"sl\"])<0: reasons.append(\"tp/sl<0\")\n",
    "    return reasons\n",
    "\n",
    "\n",
    "class Super8Indicators:\n",
    "    def __init__(self, params: Dict[str, Any]):\n",
    "        self.p = params\n",
    "\n",
    "    def _ema(self, s: pd.Series, span: int) -> pd.Series:\n",
    "        return s.ewm(span=span, adjust=False).mean()\n",
    "\n",
    "    def _adx_block(self, df: pd.DataFrame, length: int, smoothing: int, threshold: float) -> pd.DataFrame:\n",
    "        # Calculate ADX, DI+ and DI-, plus long/short conditions\n",
    "        tr = np.maximum(\n",
    "            df[\"high\"] - df[\"low\"],\n",
    "            np.maximum((df[\"high\"] - df[\"Price\"].shift(1)).abs(), (df[\"low\"] - df[\"Price\"].shift(1)).abs())\n",
    "        )\n",
    "        up = df[\"high\"].diff()\n",
    "        dn = -df[\"low\"].diff()\n",
    "        plus_dm = np.where((up > dn) & (up > 0), up, 0.0)\n",
    "        minus_dm = np.where((dn > up) & (dn > 0), dn, 0.0)\n",
    "        # Wilder's RMA for TR and directional movements\n",
    "        tr_s = _rma(pd.Series(tr, index=df.index), length)\n",
    "        plus_s = _rma(pd.Series(plus_dm, index=df.index), length)\n",
    "        minus_s = _rma(pd.Series(minus_dm, index=df.index), length)\n",
    "        plus_di = (plus_s / tr_s) * 100.0\n",
    "        minus_di = (minus_s / tr_s) * 100.0\n",
    "        denom = (plus_di + minus_di).clip(lower=1e-10)\n",
    "        dx = ((plus_di - minus_di).abs() / denom) * 100.0\n",
    "        adx = _rma(dx, smoothing)\n",
    "        out = pd.DataFrame(index=df.index)\n",
    "        out[\"adx\"] = adx\n",
    "        out[\"di_plus\"] = plus_di\n",
    "        out[\"di_minus\"] = minus_di\n",
    "        out[\"ADX_longCond\"] = (plus_di > minus_di) & (adx > threshold)\n",
    "        out[\"ADX_shortCond\"] = (plus_di < minus_di) & (adx > threshold)\n",
    "        return out\n",
    "\n",
    "    def _sar_tv(self, high: pd.Series, low: pd.Series, start: float, step: float, smax: float, price: pd.Series) -> pd.Series:\n",
    "        \"\"\"Parabolic SAR (TradingView/Wilder style).\"\"\"\n",
    "        h, l = high.to_numpy(), low.to_numpy()\n",
    "        n = len(h)\n",
    "        if n == 0:\n",
    "            return pd.Series([], index=high.index, dtype=float)\n",
    "        psar = np.zeros(n, dtype=float)\n",
    "        # Determine initial trend direction (uptrend if price increases, else downtrend)\n",
    "        up = True\n",
    "        if n >= 2:\n",
    "            if not (pd.isna(price.iloc[0]) or pd.isna(price.iloc[1])):\n",
    "                up = bool(price.iloc[1] >= price.iloc[0])\n",
    "            else:\n",
    "                up = bool((h[1] + l[1]) >= (h[0] + l[0]))\n",
    "        af = start\n",
    "        ep = float(h[0] if up else l[0])\n",
    "        psar[0] = float(l[0] if up else h[0])\n",
    "        # Iterate to calculate SAR for each bar\n",
    "        for i in range(1, n):\n",
    "            psar[i] = psar[i-1] + af * (ep - psar[i-1])\n",
    "            if up:\n",
    "                # Clamping: SAR cannot go above last two lows\n",
    "                if i >= 2:\n",
    "                    psar[i] = min(psar[i], l[i-1], l[i-2])\n",
    "                else:\n",
    "                    psar[i] = min(psar[i], l[i-1])\n",
    "                # New extreme point?\n",
    "                if h[i] > ep:\n",
    "                    ep = h[i]\n",
    "                    af = min(af + step, smax)\n",
    "                # Trend flip?\n",
    "                if l[i] < psar[i]:\n",
    "                    up = False\n",
    "                    psar[i] = ep\n",
    "                    ep = l[i]\n",
    "                    af = start\n",
    "            else:\n",
    "                # Clamping: SAR cannot go below last two highs\n",
    "                if i >= 2:\n",
    "                    psar[i] = max(psar[i], h[i-1], h[i-2])\n",
    "                else:\n",
    "                    psar[i] = max(psar[i], h[i-1])\n",
    "                # New extreme point?\n",
    "                if l[i] < ep:\n",
    "                    ep = l[i]\n",
    "                    af = min(af + step, smax)\n",
    "                # Trend flip?\n",
    "                if h[i] > psar[i]:\n",
    "                    up = True\n",
    "                    psar[i] = ep\n",
    "                    ep = h[i]\n",
    "                    af = start\n",
    "        return pd.Series(psar, index=high.index, name=\"SAR\")\n",
    "\n",
    "    def _macd(self, s: pd.Series, fast: int, slow: int, signal: int) -> pd.DataFrame:\n",
    "        fast_ma = s.ewm(span=fast, adjust=False).mean()\n",
    "        slow_ma = s.ewm(span=slow, adjust=False).mean()\n",
    "        macd_line = fast_ma - slow_ma\n",
    "        signal_line = macd_line.ewm(span=signal, adjust=False).mean()\n",
    "        hist = macd_line - signal_line\n",
    "        out = pd.DataFrame(index=s.index)\n",
    "        out[\"hist\"] = hist\n",
    "        out[\"lMACD\"] = macd_line\n",
    "        out[\"sMACD\"] = signal_line\n",
    "        return out\n",
    "\n",
    "    def _macz(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        # MAC-Z indicator (used only if MACD_options = \"MAC-Z\")\n",
    "        lengthz = self.p[\"lengthz\"]\n",
    "        lengthStdev = self.p[\"lengthStdev\"]\n",
    "        A = self.p[\"A\"]\n",
    "        B = self.p[\"B\"]\n",
    "        signalLength = self.p[\"signalLength\"]\n",
    "        vol = df[\"volume\"]\n",
    "        px = df[\"Price\"]\n",
    "        vw_mean = (vol * px).rolling(window=lengthz, min_periods=lengthz).sum() / vol.rolling(window=lengthz, min_periods=lengthz).sum()\n",
    "        vw_sd = (px - vw_mean).pow(2).rolling(window=lengthz, min_periods=lengthz).mean().pow(0.5)\n",
    "        zscore = (px - vw_mean) / vw_sd\n",
    "        macd_std = px.rolling(window=lengthStdev, min_periods=lengthStdev).std(ddof=0)\n",
    "        macd = self._macd(px, int(self.p[\"fastLength\"]), int(self.p[\"slowLength\"]), int(self.p[\"signalLength\"]))\n",
    "        macz_line = (zscore * A) + (macd[\"lMACD\"] / (macd_std * B))\n",
    "        signal = macz_line.rolling(window=signalLength, min_periods=signalLength).mean()\n",
    "        histmacz = macz_line - signal\n",
    "        return pd.DataFrame({\"histmacz\": histmacz}, index=df.index)\n",
    "\n",
    "    def compute(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Compute all technical indicators and entry/exit conditions needed for the strategy.\"\"\"\n",
    "        df = _ensure_price(df)\n",
    "        p = self.p\n",
    "        out = pd.DataFrame(index=df.index)\n",
    "\n",
    "        # EMA long and short + conditions\n",
    "        sEMA = self._ema(df[\"Price\"], int(p[\"sEma_Length\"]))\n",
    "        fEMA = self._ema(df[\"Price\"], int(p[\"fEma_Length\"]))\n",
    "        out[\"EMA_longCond\"] = (fEMA > sEMA) & (sEMA > sEMA.shift(1))\n",
    "        out[\"EMA_shortCond\"] = (fEMA < sEMA) & (sEMA < sEMA.shift(1))\n",
    "\n",
    "        # ADX indicator + conditions\n",
    "        adx_df = self._adx_block(df, int(p[\"ADX_len\"]), int(p.get(\"ADX_smo\", p[\"ADX_len\"])), float(p[\"th\"]))\n",
    "        out = out.join(adx_df)\n",
    "\n",
    "        # Parabolic SAR + conditions\n",
    "        sar = self._sar_tv(df[\"high\"], df[\"low\"], float(p[\"Sst\"]), float(p[\"Sinc\"]), float(p[\"Smax\"]), df[\"Price\"])\n",
    "        out[\"SAR\"] = sar\n",
    "        out[\"SAR_longCond\"] = (sar < df[\"Price\"])\n",
    "        out[\"SAR_shortCond\"] = (sar > df[\"Price\"])\n",
    "\n",
    "        # MACD sau MAC-Z + conditions\n",
    "        macd_df = self._macd(df[\"Price\"], int(p[\"fastLength\"]), int(p[\"slowLength\"]), int(p[\"signalLength\"]))\n",
    "        out = out.join(macd_df)\n",
    "        if p.get(\"MACD_options\", \"MACD\") == \"MAC-Z\":\n",
    "            out = out.join(self._macz(df))\n",
    "        else:\n",
    "            out[\"histmacz\"] = out[\"hist\"]\n",
    "        out[\"MACD_longCond\"] = out[\"histmacz\"] > 0\n",
    "        out[\"MACD_shortCond\"] = out[\"histmacz\"] < 0\n",
    "\n",
    "        # Bollinger Bands (BB) + band width\n",
    "        L = int(p[\"BB_Length\"])\n",
    "        mult = float(p[\"BB_mult\"])\n",
    "        mid = df[\"Price\"].rolling(window=L, min_periods=L).mean()\n",
    "        std = df[\"Price\"].rolling(window=L, min_periods=L).std(ddof=0)\n",
    "        bb_upper = mid + mult * std\n",
    "        bb_lower = mid - mult * std\n",
    "        out[\"BB_upper\"] = bb_upper\n",
    "        out[\"BB_lower\"] = bb_lower\n",
    "        out[\"BB_middle\"] = mid\n",
    "        out[\"BB_width\"] = (bb_upper - bb_lower) / mid  # lățime normalizată\n",
    "\n",
    "        # Volume (condiție volum ridicat)\n",
    "        vol_sma = df[\"volume\"].rolling(window=int(p[\"sma_Length\"]), min_periods=1).mean()\n",
    "        vol_flag = df[\"volume\"] > vol_sma * float(p[\"volume_f\"])\n",
    "        out[\"VOL_shortCond\"] = vol_flag\n",
    "        out[\"VOL_longCond\"] = vol_flag\n",
    "\n",
    "        # Praguri minime BB width (convertite din procentaj la fracție)\n",
    "        out[\"bbMinWidth01\"] = float(p[\"bbMinWidth01\"]) / 100.0\n",
    "        out[\"bbMinWidth02\"] = float(p[\"bbMinWidth02\"]) / 100.0\n",
    "\n",
    "        return out\n",
    "\n",
    "@dataclass\n",
    "class ShortParams:\n",
    "    Position: str = \"Both\"\n",
    "    TP_options: str = \"Both\"\n",
    "    SL_options: str = \"Both\"\n",
    "    tp: float = 3.6\n",
    "    sl: float = 8.0\n",
    "    atrPeriodSl: int = 21\n",
    "    multiplierPeriodSl: float = 9.5\n",
    "    trailOffset: float = 0.38\n",
    "    reverse_exit: bool = True\n",
    "    ignore_additional_entries: bool = True\n",
    "    exit_on_entry_loss: bool = False\n",
    "    start_time: Optional[pd.Timestamp] = None\n",
    "    intrabar_touch: bool = True\n",
    "    bar_path: str = \"OLHC\"\n",
    "    no_same_bar_exit: bool = True\n",
    "\n",
    "class Super8ShortBacktester:\n",
    "    def __init__(self, indicator_params: Dict[str, Any], short_params: ShortParams, use_spread: bool = True, log_return: bool = True):\n",
    "        self.indicator_params = indicator_params\n",
    "        self.short_params = short_params\n",
    "        self.use_spread = use_spread\n",
    "        self.log_return = log_return\n",
    "        self._last_bt = None  # store last backtest DataFrame if needed\n",
    "\n",
    "    def run(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        # 1) Pregătire date\n",
    "        data = df.copy()\n",
    "        if \"time\" in data.columns:\n",
    "            data[\"time\"] = pd.to_datetime(data[\"time\"], utc=True, errors=\"coerce\")\n",
    "            data = data.dropna(subset=[\"time\"]).set_index(\"time\").sort_index()\n",
    "\n",
    "        data = _ensure_price(data)\n",
    "        for col in [\"high\", \"low\", \"volume\"]:\n",
    "            if col not in data.columns:\n",
    "                raise ValueError(f\"Data missing required column '{col}'.\")\n",
    "\n",
    "        if \"Return\" not in data.columns:\n",
    "            data[\"Return\"] = np.log(data[\"Price\"] / data[\"Price\"].shift(1))\n",
    "\n",
    "        if \"Spread\" not in data.columns:\n",
    "            raise ValueError(\"Missing 'Spread' in data — compute Spread before backtesting.\")\n",
    "\n",
    "        # 2) Indicatori\n",
    "        indicators = Super8Indicators(self.indicator_params).compute(data)\n",
    "        base = data.join(indicators, how=\"left\")\n",
    "\n",
    "        # 3) Condiții clasice\n",
    "        EMA_shortCond = base.get(\"EMA_shortCond\", pd.Series(False, index=base.index)).fillna(False)\n",
    "        EMA_longCond  = base.get(\"EMA_longCond\",  pd.Series(False, index=base.index)).fillna(False)\n",
    "        ADX_shortCond = base.get(\"ADX_shortCond\", pd.Series(False, index=base.index)).fillna(False)\n",
    "        ADX_longCond  = base.get(\"ADX_longCond\",  pd.Series(False, index=base.index)).fillna(False)\n",
    "        SAR_shortCond = base.get(\"SAR_shortCond\", pd.Series(False, index=base.index)).fillna(False)\n",
    "        SAR_longCond  = base.get(\"SAR_longCond\",  pd.Series(False, index=base.index)).fillna(False)\n",
    "        VOL_shortCond = base.get(\"VOL_shortCond\", pd.Series(False, index=base.index)).fillna(False)\n",
    "        VOL_longCond  = base.get(\"VOL_longCond\",  pd.Series(False, index=base.index)).fillna(False)\n",
    "\n",
    "        # Lock: folosim doar MACD clasic\n",
    "        h = base.get(\"hist\", pd.Series(0.0, index=base.index))\n",
    "\n",
    "        MACD_shortCond = h.lt(0).fillna(False)\n",
    "        MACD_longCond  = h.gt(0).fillna(False)\n",
    "\n",
    "        # Bollinger\n",
    "        BB_upper  = base.get(\"BB_upper\",  pd.Series(np.nan, index=base.index))\n",
    "        BB_lower  = base.get(\"BB_lower\",  pd.Series(np.nan, index=base.index))\n",
    "        BB_middle = base.get(\"BB_middle\", pd.Series(np.nan, index=base.index))\n",
    "        BB_width  = base.get(\"BB_width\",  pd.Series(np.nan, index=base.index))\n",
    "        bbMin01   = base.get(\"bbMinWidth01\", pd.Series(0.05, index=base.index))  # procent → fracție\n",
    "\n",
    "        # 4) ENTRY = shortCond OR BB_short01 \n",
    "        allow_short = (self.short_params.Position != \"Long\")\n",
    "        BB_short01 = (allow_short) & (~ADX_longCond) & _crossover(base[\"high\"], BB_upper) \\\n",
    "                     & EMA_shortCond & (BB_width > bbMin01)\n",
    "        BB_short01 = BB_short01.fillna(False)\n",
    "\n",
    "        shortCond  = (allow_short) & EMA_shortCond & ADX_shortCond & SAR_shortCond & MACD_shortCond & VOL_shortCond\n",
    "        entry_cond = (shortCond | BB_short01).fillna(False)\n",
    "\n",
    "        # 5) EXIT = reverse-exit (condiții opuse) + TP/SL\n",
    "        exit_cond = (EMA_longCond | ADX_longCond | SAR_longCond | MACD_longCond).fillna(False)\n",
    "        \n",
    "        entry_sig = entry_cond.astype(\"boolean\").shift(1).fillna(False).astype(bool)\n",
    "        exit_sig  = exit_cond.astype(\"boolean\").fillna(False).astype(bool)\n",
    "\n",
    "        \n",
    "        base[\"DBG_exit_cond\"]     = exit_cond.astype(int)\n",
    "        base[\"DBG_EMA_longCond\"]  = EMA_longCond.astype(int)\n",
    "        base[\"DBG_SAR_longCond\"]  = SAR_longCond.astype(int)\n",
    "        base[\"DBG_MACD_longCond\"] = MACD_longCond.astype(int)\n",
    "\n",
    "        # 6) ATR (Wilder/RMA) + \"stair-step\" pentru SHORT\n",
    "        tr = np.maximum(\n",
    "            base[\"high\"] - base[\"low\"],\n",
    "            np.maximum((base[\"high\"] - base[\"Price\"].shift(1)).abs(),\n",
    "                       (base[\"low\"]  - base[\"Price\"].shift(1)).abs())\n",
    "        )\n",
    "        atr_rma = _rma(pd.Series(tr, index=base.index), self.short_params.atrPeriodSl)\n",
    "        atr_sl_short_raw = base[\"high\"] + atr_rma * self.short_params.multiplierPeriodSl\n",
    "\n",
    "        _open = base[\"open\"] if \"open\" in base.columns else base[\"Price\"].shift(1).fillna(base[\"Price\"])\n",
    "\n",
    "        atr_sl_short_series = pd.Series(index=base.index, dtype=float)\n",
    "        prev_stop = np.nan\n",
    "        for i in range(len(base.index)):\n",
    "            raw = float(atr_sl_short_raw.iloc[i]) if not pd.isna(atr_sl_short_raw.iloc[i]) else np.nan\n",
    "            o   = float(_open.iloc[i]) if not pd.isna(_open.iloc[i]) else raw\n",
    "            if i == 0 or np.isnan(prev_stop) or np.isnan(raw) or np.isnan(o):\n",
    "                val = raw\n",
    "            else:\n",
    "                val = min(raw, prev_stop) if o < prev_stop else raw\n",
    "            atr_sl_short_series.iloc[i] = val\n",
    "            prev_stop = val\n",
    "        base[\"DBG_ATR_SL_Short\"] = atr_sl_short_series\n",
    "\n",
    "        # 7) Donchian pentru TP (dacă e cazul)\n",
    "        if self.short_params.TP_options in (\"Both\", \"Donchian\"):\n",
    "            DClower = base[\"low\"].rolling(window=self.indicator_params[\"DClength\"],\n",
    "                                          min_periods=self.indicator_params[\"DClength\"]).min()\n",
    "        else:\n",
    "            DClower = pd.Series(np.nan, index=base.index)\n",
    "\n",
    "        # 8) Bucla de backtest (single-position; ENTRY next-bar, TP/SL & reverse same-bar)\n",
    "        position = []\n",
    "        pos = 0\n",
    "        entry_price = np.nan\n",
    "\n",
    "        for t, row in base.iterrows():\n",
    "            # respect start_time\n",
    "            if self.short_params.start_time is not None and t < self.short_params.start_time:\n",
    "                position.append(0)\n",
    "                continue\n",
    "\n",
    "            price = row[\"Price\"]\n",
    "\n",
    "            # 1) aplică intrarea semnalată pe bara anterioară (next-bar)\n",
    "            if pos == 0 and entry_sig.loc[t]:\n",
    "                pos = -1\n",
    "                entry_price = price  # intrare la close-ul barei curente\n",
    "\n",
    "            # 2) pregătește nivelurile TP/SL pentru starea curentă\n",
    "            avg_price = entry_price if (pos == -1 and not np.isnan(entry_price)) else price\n",
    "\n",
    "            # --- TP (short) ---\n",
    "            if self.short_params.TP_options == \"Both\":\n",
    "                dc_val = DClower.loc[t] if 'DClower' in locals() and t in DClower.index else np.nan\n",
    "                tp_level = np.nanmin([dc_val if not np.isnan(dc_val) else np.inf,\n",
    "                                      (1.0 - self.short_params.tp/100.0) * avg_price])\n",
    "            elif self.short_params.TP_options == \"Normal\":\n",
    "                tp_level = (1.0 - self.short_params.tp/100.0) * avg_price\n",
    "            elif self.short_params.TP_options == \"Donchian\":\n",
    "                dc_val = DClower.loc[t] if 'DClower' in locals() and t in DClower.index else np.nan\n",
    "                tp_level = dc_val if not np.isnan(dc_val) else avg_price\n",
    "            else:\n",
    "                tp_level = np.nan\n",
    "\n",
    "            # --- SL (short) ATR stair-step ---\n",
    "            atr_sl_val = atr_sl_short_series.loc[t] if t in atr_sl_short_series.index else np.nan\n",
    "            if self.short_params.SL_options == \"Both\":\n",
    "                sl_level = max(atr_sl_val, (1.0 + self.short_params.sl/100.0) * avg_price)\n",
    "            elif self.short_params.SL_options == \"Normal\":\n",
    "                sl_level = (1.0 + self.short_params.sl/100.0) * avg_price\n",
    "            elif self.short_params.SL_options == \"ATR\":\n",
    "                sl_level = atr_sl_val\n",
    "            else:\n",
    "                sl_level = np.nan\n",
    "\n",
    "            # 3) dacă suntem în poziție, evaluează ieșirile SAME-BAR (TP/SL și reverse)\n",
    "            if pos == -1:\n",
    "                tp_hit = (not np.isnan(tp_level)) and (price <= tp_level)\n",
    "                sl_hit = (not np.isnan(sl_level)) and (price >= sl_level)\n",
    "                rev_hit = bool(self.short_params.reverse_exit and exit_sig.loc[t])\n",
    "\n",
    "                if tp_hit or sl_hit or rev_hit:\n",
    "                    pos = 0\n",
    "                    entry_price = np.nan\n",
    "\n",
    "            # 4) abia acum salvezi poziția pentru bara curentă (P&L pe bară folosește această stare)\n",
    "            position.append(pos)\n",
    "\n",
    "        base[\"position\"] = position\n",
    "\n",
    "\n",
    "\n",
    "        # 9) Randamente & costuri\n",
    "        base[\"Return\"] = base[\"Return\"].fillna(0.0)\n",
    "        base[\"strategy\"] = base[\"position\"].fillna(0) * base[\"Return\"]\n",
    "\n",
    "        \n",
    "        pos_changes = base[\"position\"].astype(int).diff().fillna(base[\"position\"]).abs()\n",
    "        base[\"trades\"] = np.where(pos_changes != 0, 1, 0)\n",
    "\n",
    "        if self.use_spread:\n",
    "            base[\"Spread\"] = base[\"Spread\"].fillna(0.0)\n",
    "            base[\"strategy\"] = base[\"strategy\"] - base[\"trades\"] * base[\"Spread\"]\n",
    "\n",
    "        # 10) Cumulative returns\n",
    "        if self.log_return:\n",
    "            base[\"creturn\"]   = base[\"Return\"].cumsum().apply(np.exp)\n",
    "            base[\"cstrategy\"] = base[\"strategy\"].cumsum().apply(np.exp)\n",
    "        else:\n",
    "            base[\"creturn\"]   = (1.0 + base[\"Return\"]).cumprod()\n",
    "            base[\"cstrategy\"] = (1.0 + base[\"strategy\"]).cumprod()\n",
    "\n",
    "        self._last_bt = base.copy()\n",
    "        return base\n",
    "\n",
    "\n",
    "def _get_default(name: str) -> Any:\n",
    "    # Retrieve default value from appropriate dict\n",
    "    return indicator_params_default.get(name, short_params_default.get(name))\n",
    "\n",
    "\n",
    "# Inițializăm vectorii de optimizare\n",
    "names, start_params, bounds = prepare_optimization_vectors()\n",
    "print(\"Optimizez\", len(names), \"parametri:\", names)\n",
    "\n",
    "# Global cache for data (avoid reloading CSVs repeatedly in threads)\n",
    "all_data: Dict[str, pd.DataFrame] = {}\n",
    "\n",
    "def optimal_strategy(params_tuple: tuple, symbol: str, start: str, end: str, bar_length: str = \"H1\") -> float:\n",
    "    \"\"\"\n",
    "    Objective function for optimization: returns the NEGATIVE of strategy performance (final wealth).\n",
    "    The optimizer will minimize this (so maximizing final performance).\n",
    "    Skips invalid parameter combinations (returns a neutral value for those).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load data from cache or file\n",
    "        if symbol in all_data:\n",
    "            df = all_data[symbol]\n",
    "        else:\n",
    "            file_path = symbol_csv_path_case_insensitive(symbol) or symbol_csv_path(symbol)\n",
    "            if not file_path.exists():\n",
    "                return 1e6  # skip this trial if data not found\n",
    "            df = pd.read_csv(file_path, index_col='time', parse_dates=True)\n",
    "            df = _ensure_price(df)\n",
    "            COST_PER_SIDE = -np.log(1.0 - 0.00055)\n",
    "            df[\"Spread\"] = COST_PER_SIDE\n",
    "            all_data[symbol] = df\n",
    "\n",
    "        # Filter backtest period\n",
    "        if not end:\n",
    "            df_period = df.loc[start:]\n",
    "        else:\n",
    "            df_period = df.loc[start: end]\n",
    "        if df_period.empty:\n",
    "            return 1e6\n",
    "\n",
    "        # Construct parameter dicts from tuple\n",
    "        ind_params = indicator_params_default.copy()\n",
    "        short_vals = short_params_default.copy()\n",
    "        param_list = list(params_tuple)\n",
    "        for i, name in enumerate(names):\n",
    "            val = param_list[i]\n",
    "            if name in ind_params:\n",
    "                if name in [\"sEma_Length\", \"fEma_Length\", \"ADX_len\", \"ADX_smo\",\n",
    "                            \"fastLength\", \"slowLength\", \"signalLength\",\n",
    "                            \"sma_Length\", \"BB_Length\", \"DClength\"]:\n",
    "                    ind_params[name] = max(1, int(round(val)))\n",
    "                else:\n",
    "                    ind_params[name] = float(val)\n",
    "            else:\n",
    "                # short strategy params\n",
    "                if name == \"atrPeriodSl\":\n",
    "                    short_vals[name] = max(1, int(round(val)))\n",
    "                else:\n",
    "                    short_vals[name] = float(val)\n",
    "\n",
    "        # Set non-optimized options to default\n",
    "        ind_params[\"MACD_options\"] = indicator_params_default[\"MACD_options\"]\n",
    "        ind_params[\"lengthz\"] = indicator_params_default[\"lengthz\"]\n",
    "        ind_params[\"lengthStdev\"] = indicator_params_default[\"lengthStdev\"]\n",
    "        ind_params[\"A\"] = indicator_params_default[\"A\"]\n",
    "        ind_params[\"B\"] = indicator_params_default[\"B\"]\n",
    "        ind_params[\"bbMinWidth02\"] = indicator_params_default[\"bbMinWidth02\"]\n",
    "\n",
    "        # Skip invalid combinations\n",
    "        if not is_param_combo_valid(ind_params, short_vals):\n",
    "            return 1e6\n",
    "\n",
    "        # Run backtest for this parameter set\n",
    "        short_obj = ShortParams(\n",
    "            Position=\"Both\", TP_options=\"Both\", SL_options=\"Both\",\n",
    "            tp=short_vals[\"tp\"], sl=short_vals[\"sl\"],\n",
    "            atrPeriodSl=short_vals[\"atrPeriodSl\"],\n",
    "            multiplierPeriodSl=short_vals[\"multiplierPeriodSl\"],\n",
    "            trailOffset=short_vals[\"trailOffset\"]\n",
    "        )\n",
    "        backtester = Super8ShortBacktester(\n",
    "            indicator_params=ind_params,\n",
    "            short_params=short_obj,\n",
    "            use_spread=True,\n",
    "            log_return=True\n",
    "        )\n",
    "        bt = backtester.run(df_period)\n",
    "        eq  = bt[\"cstrategy\"].astype(float)\n",
    "        bh  = bt[\"creturn\"].astype(float)\n",
    "        perf = float(eq.iloc[-1])\n",
    "        bhf  = float(bh.iloc[-1]) if len(bh) else 1.0\n",
    "\n",
    "        alpha  = (perf / bhf) if bhf > 0 else 0.0\n",
    "        r      = bt[\"strategy\"].fillna(0.0).values\n",
    "        mu     = float(np.mean(r))\n",
    "        sd     = float(np.std(r, ddof=1)) if len(r) > 1 else 0.0\n",
    "        periods_per_year = 365*12  # H2 aprox\n",
    "        sharpe = (mu/sd*np.sqrt(periods_per_year)) if sd > 0 else 0.0\n",
    "\n",
    "        # penalizează seturi cu prea multe/puține tranzacții\n",
    "        pos = bt[\"position\"].astype(int)\n",
    "        trades = int(((pos != pos.shift(1)).fillna(pos!=0)).sum())\n",
    "        T = len(bt)\n",
    "        tr_rate = trades / max(T,1)\n",
    "        pen_tr = 0.0\n",
    "        pen_tr += 2.0 * max(0.0, tr_rate - 0.04)   # >4% bare cu trade\n",
    "        pen_tr += 2.0 * max(0.0, 0.01 - tr_rate)   # <1% bare cu trade\n",
    "\n",
    "        score = (alpha * max(0.0, sharpe)) - pen_tr\n",
    "        return -score\n",
    "\n",
    "\n",
    "    except Exception:\n",
    "        # On any error, return neutral value (so optimizer ignores/improves it)\n",
    "        return -1.0\n",
    "\n",
    "def optimize_strategy_parallel(symbol, start_par, bnds, start, end, bar_length, max_workers=4, seed=None):\n",
    "    import numpy as np\n",
    "    from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "    from scipy.optimize import minimize\n",
    "\n",
    "    rng = np.random.default_rng(seed)\n",
    "    def rand_start():\n",
    "        return tuple(rng.uniform(lo, hi) for (lo, hi) in bnds)\n",
    "\n",
    "    best = None\n",
    "    starts = [start_par] + [rand_start() for _ in range(max_workers - 1)]\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as ex:\n",
    "        futs = [ex.submit(\n",
    "            minimize, optimal_strategy, s,\n",
    "            args=(symbol, start, end or '', bar_length),\n",
    "            method=\"Powell\", bounds=bnds,\n",
    "            options={\"maxiter\": 220, \"xtol\": 1e-2, \"ftol\": 1e-2}\n",
    "        ) for s in starts]\n",
    "\n",
    "        for f in as_completed(futs):\n",
    "            try:\n",
    "                r = f.result()\n",
    "                if r.success and (best is None or r.fun < best.fun):\n",
    "                    best = r\n",
    "            except Exception as e:\n",
    "                print(\"Eroare în calcul:\", e)\n",
    "    return best\n",
    "\n",
    "\n",
    "\n",
    "def manage_symbol_data(symbol: str, file_path: Path) -> None:\n",
    "    \"\"\"Verifică existența fișierului local pentru simbol.\"\"\"\n",
    "    resolved = file_path.resolve()\n",
    "    if resolved.exists():\n",
    "        return\n",
    "    alt_path = symbol_csv_path_case_insensitive(symbol)\n",
    "    if alt_path is not None:\n",
    "        return\n",
    "    raise FileNotFoundError(\n",
    "        f\"Fișierul de date pentru {symbol} nu există: '{resolved}'.\\n\"\n",
    "        f\"Verifică DATA_DIR={DATA_DIR} sau setează SUPER8_DATA_DIR către folderul cu CSV-uri.\"\n",
    "    )\n",
    "\n",
    "def main(\n",
    "    symbols: Optional[List[str]] = None,\n",
    "    output_path: Optional[str] = None,\n",
    "    cfg_path: Optional[str] = None,\n",
    "    require_credentials: bool = False,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"Rulează optimizarea pe lista de simboluri indicată.\"\"\"\n",
    "    start_date = \"2021-06-01\"\n",
    "\n",
    "    if symbols is None:\n",
    "        try:\n",
    "            symbols = load_symbol_universe(data_dir=DATA_DIR)\n",
    "        except Exception as exc:\n",
    "            raise RuntimeError(\n",
    "                \"Nu am reușit să determin lista de simboluri. Configurează SUPER8_SYMBOLS_FILE sau folderul cu CSV-uri.\"\n",
    "            ) from exc\n",
    "    if not symbols:\n",
    "        raise ValueError(\"Lista de simboluri este goală.\")\n",
    "\n",
    "    load_binance_credentials(cfg_path, required=require_credentials)\n",
    "\n",
    "    df_results = pd.DataFrame(columns=[\"Symbol\", \"Parameters\", \"Performance\", \"Trades\"])\n",
    "\n",
    "    for symbol in symbols:\n",
    "        file_path = symbol_csv_path(symbol)\n",
    "        try:\n",
    "            manage_symbol_data(symbol, file_path)\n",
    "            resolved_path = symbol_csv_path_case_insensitive(symbol) or file_path\n",
    "        except Exception as e:\n",
    "            print(f\"Nu s-au putut obține datele pentru {symbol}: {e}\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            print(f\"[{symbol}] Citim datele din: {resolved_path}\")\n",
    "            data = pd.read_csv(resolved_path, index_col='time', parse_dates=True)\n",
    "        except Exception as e:\n",
    "            print(f\"Eroare la citirea fișierului pentru {symbol}: {e}\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            data = _ensure_price(data)\n",
    "            COST_PER_SIDE = -np.log(1.0 - 0.00055)   # ≈ 0.00055015 log-return\n",
    "            data[\"Spread\"] = COST_PER_SIDE\n",
    "        except Exception as e:\n",
    "            print(f\"[{symbol}] Eroare la pregătirea datelor (Price/Spread): {e}\")\n",
    "            continue\n",
    "\n",
    "        all_data[symbol] = data\n",
    "\n",
    "        last_idx = data.index.max()\n",
    "        last_date_str = last_idx.strftime(\"%Y-%m-%d\") if pd.notna(last_idx) else \"\"\n",
    "        attempt = 0\n",
    "        max_attempts = 4\n",
    "        success = False\n",
    "        last_exception = None\n",
    "\n",
    "        while attempt < max_attempts and not success:\n",
    "            try:\n",
    "                print(f\"Optimizare pentru simbolul {symbol} pe perioada {start_date} - {last_date_str}\")\n",
    "                opt_result = optimize_strategy_parallel(symbol, start_params, bounds, start_date, \"\", \"H2\")\n",
    "                if opt_result is None or not opt_result.success:\n",
    "                    raise ValueError(\"Optimizarea a eșuat.\")\n",
    "\n",
    "                best_params = opt_result.x\n",
    "                output_params = []\n",
    "                for i, name in enumerate(names):\n",
    "                    val = best_params[i]\n",
    "                    if name in [\"sEma_Length\", \"fEma_Length\", \"ADX_len\", \"ADX_smo\",\n",
    "                                \"fastLength\", \"slowLength\", \"signalLength\",\n",
    "                                \"sma_Length\", \"BB_Length\", \"DClength\", \"atrPeriodSl\"]:\n",
    "                        v = max(1, int(round(val)))\n",
    "                    else:\n",
    "                        v = round(float(val), 3)\n",
    "                    output_params.append(v)\n",
    "\n",
    "                ind_params_opt = indicator_params_default.copy()\n",
    "                short_vals_opt = short_params_default.copy()\n",
    "                for i, name in enumerate(names):\n",
    "                    if name in ind_params_opt:\n",
    "                        if name in [\"sEma_Length\", \"fEma_Length\", \"ADX_len\", \"ADX_smo\",\n",
    "                                    \"fastLength\", \"slowLength\", \"signalLength\",\n",
    "                                    \"sma_Length\", \"BB_Length\", \"DClength\"]:\n",
    "                            ind_params_opt[name] = max(1, int(round(best_params[i])))\n",
    "                        else:\n",
    "                            ind_params_opt[name] = float(best_params[i])\n",
    "                    else:\n",
    "                        if name == \"atrPeriodSl\":\n",
    "                            short_vals_opt[name] = max(1, int(round(best_params[i])))\n",
    "                        else:\n",
    "                            short_vals_opt[name] = float(best_params[i])\n",
    "\n",
    "                ind_params_opt[\"MACD_options\"] = indicator_params_default[\"MACD_options\"]\n",
    "                ind_params_opt[\"lengthz\"] = indicator_params_default[\"lengthz\"]\n",
    "                ind_params_opt[\"lengthStdev\"] = indicator_params_default[\"lengthStdev\"]\n",
    "                ind_params_opt[\"A\"] = indicator_params_default[\"A\"]\n",
    "                ind_params_opt[\"B\"] = indicator_params_default[\"B\"]\n",
    "                ind_params_opt[\"bbMinWidth02\"] = indicator_params_default[\"bbMinWidth02\"]\n",
    "\n",
    "                if not is_param_combo_valid(ind_params_opt, short_vals_opt):\n",
    "                    print(f\"Set de parametri invalid pentru {symbol}: {why_invalid(ind_params_opt, short_vals_opt)} (ignorat).\")\n",
    "                    break\n",
    "\n",
    "                short_obj_opt = ShortParams(\n",
    "                    Position=\"Both\", TP_options=\"Both\", SL_options=\"Both\",\n",
    "                    tp=short_vals_opt[\"tp\"], sl=short_vals_opt[\"sl\"],\n",
    "                    atrPeriodSl=short_vals_opt[\"atrPeriodSl\"],\n",
    "                    multiplierPeriodSl=short_vals_opt[\"multiplierPeriodSl\"],\n",
    "                    trailOffset=short_vals_opt[\"trailOffset\"]\n",
    "                )\n",
    "                backtester_opt = Super8ShortBacktester(indicator_params=ind_params_opt, short_params=short_obj_opt, use_spread=True, log_return=True)\n",
    "                bt_full = backtester_opt.run(data.loc[start_date:])\n",
    "\n",
    "                final_perf = float(bt_full[\"cstrategy\"].iloc[-1]) if not bt_full.empty else 1.0\n",
    "                pos_series = bt_full[\"position\"]\n",
    "                entry_events = (pos_series != 0) & (pos_series.shift(1).fillna(0) == 0)\n",
    "                num_trades = int(entry_events.sum())\n",
    "\n",
    "                new_row = {\n",
    "                    \"Symbol\": symbol,\n",
    "                    \"Parameters\": output_params,\n",
    "                    \"Performance\": final_perf,\n",
    "                    \"Trades\": num_trades\n",
    "                }\n",
    "                df_results = pd.concat([df_results, pd.DataFrame([new_row])], ignore_index=True)\n",
    "                success = True\n",
    "\n",
    "            except (ConnectionError, TimeoutError, OSError) as ex:\n",
    "                last_exception = ex\n",
    "                print(f\"Eroare temporară la simbolul {symbol}: {ex}. Se reîncearcă.\")\n",
    "            except Exception as ex:\n",
    "                last_exception = ex\n",
    "                print(f\"Eroare la simbolul {symbol}: {ex}. Trecem la următorul simbol.\")\n",
    "                break\n",
    "            finally:\n",
    "                attempt += 1\n",
    "                if not success:\n",
    "                    print(f\"Încercare: {attempt}\")\n",
    "                    if attempt >= max_attempts:\n",
    "                        print(f\"Procesul pentru {symbol} a eșuat: număr maxim de încercări atins.\")\n",
    "                    elif isinstance(last_exception, (ConnectionError, TimeoutError, OSError)):\n",
    "                        wait_time = 5 * attempt\n",
    "                        print(f\"Așteptăm {wait_time} secunde înainte de următoarea încercare.\")\n",
    "                        time.sleep(wait_time)\n",
    "\n",
    "    if not df_results.empty:\n",
    "        df_results = df_results.sort_values(by=\"Performance\", ascending=False, ignore_index=True)\n",
    "\n",
    "    if output_path:\n",
    "        if df_results.empty:\n",
    "            print(\"[Avertisment] Nu există rezultate pentru a fi salvate.\")\n",
    "        else:\n",
    "            save_results(df_results, output_path)\n",
    "\n",
    "    return df_results\n",
    "\n",
    "\n",
    "# --- Exemplu de rulare a funcției main ---\n",
    "if __name__ == \"__main__\":\n",
    "    start_time = time.time()\n",
    "    try:\n",
    "        symbols = load_symbol_universe()\n",
    "    except Exception as exc:\n",
    "        raise SystemExit(f\"[Eroare] Nu am putut construi lista de simboluri: {exc}\") from exc\n",
    "\n",
    "    results_df = main(\n",
    "        symbols=symbols,\n",
    "        cfg_path=BINANCE_CFG_PATH,\n",
    "        output_path=RESULTS_PATH_DEFAULT,\n",
    "    )\n",
    "\n",
    "    end_time = time.time()\n",
    "    print(f\"Timpul total de execuție: {end_time - start_time:.2f} secunde\")\n",
    "    print(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificare rapidă a variabilelor de mediu și a căilor configurate\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "def verifica_configuratia_super8():\n",
    "    campuri = {\n",
    "        \"SUPER8_DATA_DIR\": os.getenv(\"SUPER8_DATA_DIR\"),\n",
    "        \"BINANCE_CFG_PATH\": os.getenv(\"BINANCE_CFG_PATH\"),\n",
    "        \"SUPER8_RESULTS_PATH\": os.getenv(\"SUPER8_RESULTS_PATH\"),\n",
    "        \"SUPER8_SYMBOLS_FILE\": os.getenv(\"SUPER8_SYMBOLS_FILE\"),\n",
    "    }\n",
    "    rapoarte = []\n",
    "    for cheie, valoare in campuri.items():\n",
    "        if valoare:\n",
    "            cale = Path(valoare).expanduser()\n",
    "            rapoarte.append({\n",
    "                \"variabila\": cheie,\n",
    "                \"valoare\": valoare,\n",
    "                \"exista\": cale.exists(),\n",
    "                \"tip\": \"fisier\" if cale.is_file() else (\"director\" if cale.is_dir() else \"intrare\"),\n",
    "            })\n",
    "        else:\n",
    "            rapoarte.append({\n",
    "                \"variabila\": cheie,\n",
    "                \"valoare\": None,\n",
    "                \"exista\": False,\n",
    "                \"tip\": \"nedefinit\"\n",
    "            })\n",
    "    return rapoarte\n",
    "\n",
    "verifica_configuratia_super8()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rulare backtest (poți ajusta lista de simboluri sau parametrul cfg_path)\n",
    "symbol_list = load_symbol_universe()\n",
    "results_df = main(symbols=symbol_list, cfg_path=BINANCE_CFG_PATH)\n",
    "results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvare rezultate în CSV (schimbă output_path dacă dorești altă locație)\n",
    "output_path = RESULTS_PATH_DEFAULT\n",
    "save_path = save_results(results_df, output_path)\n",
    "save_path\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}